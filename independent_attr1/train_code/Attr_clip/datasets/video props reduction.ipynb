{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0567e7",
   "metadata": {},
   "source": [
    "# prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19410e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:37:16.343902Z",
     "start_time": "2022-10-05T16:37:16.337268Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import sys\n",
    "sys.path.append(\"/home/xuyue/mvit_clean/\")\n",
    "# print(sys.path)\n",
    "import os\n",
    "import os.path as osp\n",
    "from collections import defaultdict, Counter\n",
    "import multiprocessing as mproc\n",
    "import tqdm\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# local code\n",
    "from configs.defaults import get_cfg\n",
    "from datasets.build import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70da975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:37:16.974985Z",
     "start_time": "2022-10-05T16:37:16.967423Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# data_dir = [\n",
    "#     [\"salads\", \"FiftySalads\"],\n",
    "#     [\"egtea\", \"EgteaGaze\"],\n",
    "#     [\"charades\", \"CharadesEgo\"],\n",
    "#     [\"ego4d\", \"Ego4dAction\"],\n",
    "#     [\"egoclip\", \"EgoClip_EgoMCQ\"],\n",
    "\n",
    "#     [\"Epic\", \"/ssd/FAST_DATA/epic-kitchens\"],\n",
    "#     [\"FiftySalads\", \"/hdd/DATA/50salad\"],\n",
    "#     [\"Breakfast\", \"/hdd/DATA/breakfast\"],\n",
    "#     [\"IKEA\", \"/hdd/DATA/ikea_asm_dataset_public\"],\n",
    "#     [\"EgteaGaze\", \"/ssd/FAST_DATA/EGTEA_GAZE+\"],\n",
    "#     [\"CharadesEgo\", \"/hdd/DATA/charades-ego\"],\n",
    "#     [\"Ego4dAction\", \"/hdd/DATA/Ego4d/ego4d-fho/\"],\n",
    "#     [\"SthElse\", \"/hdd/DATA/something-else/\"],\n",
    "#     [\"EgoClip_EgoMCQ\", \"/hdd/DATA/Ego4d/ego4d-fho/\"],\n",
    "# ]\n",
    "\n",
    "data_dir = [\n",
    "    [\"egtea\", \"EgteaGaze\"],\n",
    "    [\"EgteaGaze\", \"/ssd/FAST_DATA/EGTEA_GAZE+\"],\n",
    "]\n",
    "\n",
    "def get_dataset_by_name(ds_name, split, num_frame=8, frame_gap=24):\n",
    "    root = None\n",
    "    for k, v in data_dir:\n",
    "        if k.lower() == ds_name.lower():\n",
    "            if v[0] == \"/\": # is dir\n",
    "                root = v\n",
    "                ds_name = k\n",
    "            else:\n",
    "                ds_name = v\n",
    "            \n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_list([\n",
    "        \"TRAIN.DATASET\", ds_name,\n",
    "        \"TEST.DATASET\", ds_name,\n",
    "        \"DATA.PATH_TO_DATA_DIR\", root,\n",
    "        \"DATA.NUM_FRAMES\", str(num_frame),\n",
    "        \"DATA.FPS\", str(frame_gap),\n",
    "    ])\n",
    "    dset = build_dataset(ds_name, cfg, split)\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86b5aa",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca2175f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:37:29.248054Z",
     "start_time": "2022-10-05T16:37:19.001279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading EgteaGaze\n",
      "length = 8300\n"
     ]
    }
   ],
   "source": [
    "train_datasets = {}\n",
    "\n",
    "for name in [\n",
    "    # \"Epic\",\n",
    "    # \"FiftySalads\",\n",
    "    # \"Breakfast\",\n",
    "    # \"IKEA\",\n",
    "    \"EgteaGaze\",\n",
    "#     \"CharadesEgo\",\n",
    "    # \"Ego4dAction\",\n",
    "    # \"SthElse\",\n",
    "]:\n",
    "    print(\"loading\", name)\n",
    "    train_datasets[name] = get_dataset_by_name(name, \"train\")\n",
    "    print(\"length =\", len(train_datasets[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3405897",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f7167d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:37:29.392902Z",
     "start_time": "2022-10-05T16:37:29.250572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EgteaGaze 106\n"
     ]
    }
   ],
   "source": [
    "idx_by_verb = {}\n",
    "\n",
    "for name, dset in train_datasets.items():\n",
    "    cnt = defaultdict(list)\n",
    "    for i, x in enumerate(dset.video_records):\n",
    "        verb = x.verb_str\n",
    "        # print(\"verb=\",verb)\n",
    "        if type(verb)==list:\n",
    "            verb = \",\".join(verb)\n",
    "        cnt[verb].append(i)\n",
    "    idx_by_verb[name] = cnt\n",
    "    print(name, len(cnt))\n",
    "\n",
    "# print(idx_by_verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef3766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T03:08:10.316328Z",
     "start_time": "2022-09-26T03:08:10.307907Z"
    }
   },
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ac05bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:39:49.198737Z",
     "start_time": "2022-10-05T16:37:29.394364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "os.environ['BERT_BASE_DIR']='/home/xuyue/pretrain_models/'\n",
    "\n",
    "device = \"cuda\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('/home/xuyue/pretrain_models/bert-base-uncased.tar.gz') #'bert-base-uncased')\n",
    "bert_model.eval().to(device)\n",
    "\n",
    "print(\"loaded\")\n",
    "\n",
    "def extract_bert_feature(sentence):\n",
    "    \n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "\n",
    "    # Tokenized input\n",
    "    text = f\"[CLS] {sentence} [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    segments_ids = [0]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = bert_model(tokens_tensor, segments_tensors)\n",
    "    # We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "    assert len(encoded_layers) == 12\n",
    "    \n",
    "    return encoded_layers[0][0, 0, :]   # [1, n_token, dim] -> [dim], use [CLS] embedding\n",
    "\n",
    "feat = extract_bert_feature(\"hello world\")\n",
    "print(feat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3355a49b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:40:04.914196Z",
     "start_time": "2022-10-05T16:39:49.201395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EgteaGaze\n"
     ]
    }
   ],
   "source": [
    "verb_stat = {}\n",
    "\n",
    "for name, cnt in idx_by_verb.items():\n",
    "    print(name)\n",
    "    stat = {}\n",
    "    \n",
    "    for verb, idx in cnt.items():\n",
    "        b = extract_bert_feature(verb).cpu().numpy()\n",
    "        stat[verb] = {\n",
    "            \"count\": len(idx),\n",
    "            \"bert\": b,\n",
    "        }\n",
    "        \n",
    "    verb_stat[name] = stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd37bd",
   "metadata": {},
   "source": [
    "# Semantic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4163fd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T16:40:09.771072Z",
     "start_time": "2022-10-05T16:40:09.445430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/qpic/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import scoreatpercentile\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "def _select_sigma(x, percentile=25):\n",
    "    normalize = 1.349\n",
    "    IQR = (scoreatpercentile(x, 75) - scoreatpercentile(x, 25)) / normalize\n",
    "    std_dev = np.std(x, axis=0, ddof=1)\n",
    "    if IQR > 0:\n",
    "        return np.minimum(std_dev, IQR)\n",
    "    else:\n",
    "        return std_dev\n",
    "\n",
    "def bw_scott(x, kernel=None):\n",
    "    A = _select_sigma(x)\n",
    "    n = len(x)\n",
    "    return 1.059 * A * n ** (-0.2)\n",
    "\n",
    "def bw_silverman(x, kernel=None):\n",
    "    A = _select_sigma(x)\n",
    "    n = len(x)\n",
    "    return 0.9 * A * n ** (-0.2)\n",
    "\n",
    "def logsumexp(x, axis=-1):\n",
    "    mx = np.max(x, axis=axis)\n",
    "    return np.log(np.sum(np.exp(x - np.expand_dims(mx, axis)), axis)) + mx\n",
    "\n",
    "class KdeDensity(object):\n",
    "    def __init__(self, y, weight=None, sigma=\"scott\"):\n",
    "        y = np.array(y)\n",
    "        \n",
    "        if weight is None:\n",
    "            weight = np.ones((y.shape[0],))\n",
    "        elif isinstance(weight, list):\n",
    "            weight = np.array(weight)\n",
    "        weight = weight * 1.0 / weight.sum()\n",
    "        \n",
    "        if isinstance(sigma, str):\n",
    "            bw_func = {\n",
    "                \"scott\": bw_scott,\n",
    "                \"silverman\": bw_silverman,\n",
    "            }[sigma]\n",
    "            \n",
    "            sigma = np.array([bw_func(y[:, i].tolist()) for i in range(y.shape[1])])\n",
    "        elif isinstance(sigma, int) or isinstance(sigma, float):\n",
    "            sigma = np.ones((y.shape[1],))*sigma\n",
    "        elif isinstance(sigma, list):\n",
    "            sigma = np.array(sigma)\n",
    "\n",
    "        self.y = y\n",
    "        self.weight = weight\n",
    "        self.sigma = sigma\n",
    "        self.log_const = np.log(sigma * math.sqrt(2*math.pi)).sum()\n",
    "        \n",
    "        \n",
    "    def __logsumexp(self, x, axis=-1):\n",
    "        mx = np.max(x, axis=axis)\n",
    "        return np.log(np.sum(np.exp(x - np.expand_dims(mx, axis)), axis)) + mx\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"estimate log likelihood\"\"\"\n",
    "        x = np.array(x)\n",
    "        dist = x[:, np.newaxis, :] - self.y[np.newaxis, :, :] # n_query, n_base_sample, dim\n",
    "        dist = dist / self.sigma[np.newaxis, np.newaxis, :]\n",
    "        dist = np.log(self.weight)[np.newaxis, :] - 0.5 * np.square(dist).sum(-1)\n",
    "        dist = self.__logsumexp(dist, axis=1) - self.log_const\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885c0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T09:24:42.915682Z",
     "start_time": "2022-09-26T09:24:42.867072Z"
    }
   },
   "source": [
    "# Egtea: delete tail class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8645fa67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T17:10:26.547294Z",
     "start_time": "2022-09-27T17:10:25.666724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "5\n",
      "7885 [('EgteaGaze', 7885)]\n",
      "10\n",
      "7470 [('EgteaGaze', 7470)]\n",
      "20\n",
      "6640 [('EgteaGaze', 6640)]\n"
     ]
    }
   ],
   "source": [
    "datasetA = [{\n",
    "    \"verb\": v,\n",
    "    \"count\": x[\"count\"],\n",
    "    \"bert\": x[\"bert\"],\n",
    "    }\n",
    "    for v, x in verb_stat[\"EgteaGaze\"].items()\n",
    "]\n",
    "\n",
    "datasetB = [{\n",
    "    \"verb\": v,\n",
    "    \"count\": x[\"count\"],\n",
    "    \"bert\": x[\"bert\"],\n",
    "    \"dataset\": name,\n",
    "    }\n",
    "    for name, stat in verb_stat.items() for v, x in stat.items() if name in [\"EgteaGaze\"]\n",
    "]\n",
    "\n",
    "print(len(datasetA))\n",
    "\n",
    "bert_a = np.array([x['bert'] for x in datasetA])\n",
    "count_a = np.array([x['count'] for x in datasetA], dtype=float)\n",
    "\n",
    "bert_b = np.array([x['bert'] for x in datasetA])\n",
    "count_b = np.array([x['count'] for x in datasetA], dtype=float)\n",
    "\n",
    "kde = KdeDensity(bert_a, weight = count_a, sigma=0.5)\n",
    "logp_b = kde(bert_b)\n",
    "cls_id_ordered = sorted(range(len(logp_b)), key=lambda i:logp_b[i], reverse=True)\n",
    "\n",
    "# print(kde)\n",
    "# print(\"logp_b=\",logp_b)\n",
    "# print(\"logp_b.len=\",len(logp_b))\n",
    "# print(\"cls_id_ordered=\",cls_id_ordered)\n",
    "\n",
    "for percent in [5, 10, 20]:\n",
    "    print(percent)\n",
    "\n",
    "    num_to_select = int(np.sum(count_a)*0.01*(100-percent))\n",
    "    \n",
    "\n",
    "    cur_index = 0\n",
    "    selected_sample = []\n",
    "    num_per_ds = defaultdict(int)\n",
    "    \n",
    "    while len(selected_sample) < num_to_select:\n",
    "        cls_id = cls_id_ordered[cur_index]\n",
    "        cur_index += 1\n",
    "        \n",
    "        dsname = datasetB[cls_id][\"dataset\"]\n",
    "        verb = datasetB[cls_id][\"verb\"]\n",
    "        all_indices = idx_by_verb[dsname][verb]\n",
    "        \n",
    "        np.random.shuffle(all_indices)\n",
    "        num = min(datasetB[cls_id][\"count\"], num_to_select-len(selected_sample))\n",
    "        num_per_ds[dsname] += num\n",
    "        idx = all_indices[:num]\n",
    "        selected_sample += [[dsname, x] for x in idx]\n",
    "    \n",
    "    \n",
    "    # path = f\"video_property/selection/Egtea_reduction_{percent}p.json\"\n",
    "    path = f\"./reduction/Egtea_reduction_{percent}p.json\"\n",
    "\n",
    "    with open(path, \"w\") as fp:\n",
    "        json.dump(selected_sample, fp)\n",
    "    print(len(selected_sample), [(k,v) for k,v in num_per_ds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023f333",
   "metadata": {},
   "source": [
    "# Egtea: delete head class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536d9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "5\n",
      "7885 [('EgteaGaze', 7885)]\n",
      "10\n",
      "7470 [('EgteaGaze', 7470)]\n",
      "20\n",
      "6640 [('EgteaGaze', 6640)]\n"
     ]
    }
   ],
   "source": [
    "datasetA = [{\n",
    "    \"verb\": v,\n",
    "    \"count\": x[\"count\"],\n",
    "    \"bert\": x[\"bert\"],\n",
    "    }\n",
    "    for v, x in verb_stat[\"EgteaGaze\"].items()\n",
    "]\n",
    "\n",
    "datasetB = [{\n",
    "    \"verb\": v,\n",
    "    \"count\": x[\"count\"],\n",
    "    \"bert\": x[\"bert\"],\n",
    "    \"dataset\": name,\n",
    "    }\n",
    "    for name, stat in verb_stat.items() for v, x in stat.items() if name in [\"EgteaGaze\"]\n",
    "]\n",
    "\n",
    "print(len(datasetA))\n",
    "\n",
    "bert_a = np.array([x['bert'] for x in datasetA])\n",
    "count_a = np.array([x['count'] for x in datasetA], dtype=float)\n",
    "\n",
    "bert_b = np.array([x['bert'] for x in datasetA])\n",
    "count_b = np.array([x['count'] for x in datasetA], dtype=float)\n",
    "\n",
    "kde = KdeDensity(bert_a, weight = count_a, sigma=0.5)\n",
    "logp_b = kde(bert_b)\n",
    "cls_id_ordered = sorted(range(len(logp_b)), key=lambda i:logp_b[i], reverse=False)\n",
    "\n",
    "# print(kde)\n",
    "# print(\"logp_b=\",logp_b)\n",
    "# print(\"logp_b.len=\",len(logp_b))\n",
    "# print(\"cls_id_ordered=\",cls_id_ordered)\n",
    "\n",
    "for percent in [5, 10, 20]:\n",
    "    print(percent)\n",
    "\n",
    "    num_to_select = int(np.sum(count_a)*0.01*(100-percent))\n",
    "    \n",
    "\n",
    "    cur_index = 0\n",
    "    selected_sample = []\n",
    "    num_per_ds = defaultdict(int)\n",
    "    \n",
    "    while len(selected_sample) < num_to_select:\n",
    "        cls_id = cls_id_ordered[cur_index]\n",
    "        cur_index += 1\n",
    "        \n",
    "        dsname = datasetB[cls_id][\"dataset\"]\n",
    "        verb = datasetB[cls_id][\"verb\"]\n",
    "        all_indices = idx_by_verb[dsname][verb]\n",
    "        \n",
    "        np.random.shuffle(all_indices)\n",
    "        num = min(datasetB[cls_id][\"count\"], num_to_select-len(selected_sample))\n",
    "        num_per_ds[dsname] += num\n",
    "        idx = all_indices[:num]\n",
    "        selected_sample += [[dsname, x] for x in idx]\n",
    "    \n",
    "    \n",
    "    # path = f\"video_property/selection/Egtea_reduction_{percent}p.json\"\n",
    "    path = f\"./reduction/Egtea_reduction_{percent}p_reverse.json\"\n",
    "\n",
    "    with open(path, \"w\") as fp:\n",
    "        json.dump(selected_sample, fp)\n",
    "    print(len(selected_sample), [(k,v) for k,v in num_per_ds.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('qpic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "d329ba152077e0894feb28c06680287b15cf392e06d1dead10eb6c1f18f7df8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
